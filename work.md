# 作業日誌

## 2025/12/18「雲居研ゼミ」

### 研究して欲しいこと

### 課題

- colpali のアーキテクチャ図の ViE と LLM の間の細いやつを見つける

```
役割： 「通訳」

Vision Encoder (SigLIP) が出力するのは、画像の特徴を表すベクトル（SigLIP-So400m の場合、通常 1,152次元）。

LLM (Gemma-2B) が入力として受け付けるのは、テキスト埋め込み空間のベクトル（Gemma-2B の場合、通常 2,048次元）。

この次元数と空間の意味（画像空間 vs 言語空間）が異なるため、この proj. 層が画像ベクトルに行列計算を行い、LLM が「言葉のトークン」として処理できる形式（2,048次元）に変換（マッピング）。

論文での記述：

「SigLIP-So400m/14 のパッチ埋め込みを、Gemma-2B のテキストベクトル空間に射影する」と記載 。
```

- ドキュメントを 4 分割するとどうなるのか

```
1パッチが担当する物理領域が小さくなり、細かい文字（日本語の小さい店名など）に強くなりやすい

なぜ分割するのか？
（解像度の壁）ColPali (PaliGemma) は、基本的に画像を 448×448 程度（SigLIPの仕様に基づく）にリサイズして入力。
A4サイズの細かい契約書や論文を 448×448 に縮小すると、文字が潰れて読めない。
4分割のアプローチ：元の画像を4つの領域（左上、右上、左下、右下など）に切り分けます。
それぞれの切り取った画像を 448×448 にリサイズします。
こうすると、元画像全体を縮小するよりも、実質的な解像度が4倍 になります。
これらを個別にエンコードし、シーケンスとして繋げて LLM に読ませます。
```

- proj.とはなんなのか

```
2つある線形射影層のこと
①Vision Encoder (SigLIP)で 1152 次元 → 線形射影層（学習された重み行列を使用）で 2048 次元
②Gemma から出てくる高次元ベクトル（2048次元）→ 128次元へ
```

## 2025/12/19〜29「作業」

### colpali って何するもの

- 前提：レシートの PDF から会社名のあるページを探す

1. PDF レンダリング
   - 画像の縦横サイズに基づいた巨大な行列（テンソル）を作成、各ピクセルに対し、**R（赤）、G（緑）、B（青）**の 3 つのチャネルで「0〜255」の整数値が割り当て
   - 448×448 ピクセルの場合(448, 448, 3)
2. 数値の正規化と整形（SigLIP が計算しやすいように）
   - ColPali が使用する PaliGemma モデルの入力サイズ（例：448×448）に合わせて、画像を拡大または縮小
   - 0〜255 の整数を「0.0〜1.0」の浮動小数点数に変換
   - データセット全体の平均値を引き、標準偏差で割る（色の偏りをなくす）
   - 計算しやすいように軸入れ替え(C, H, W)（色、高さ、幅）に入れ替え
3. パッチ分割
   - 画像を 14×14 ピクセルの小さな「パッチ」に分割（448×448 の画像であれば、縦 32 個 × 横 32 個 ＝ 合計 1024 個のパッチ）
     - 理想的なパッチ：クエリの 1 単語が数パッチにわたって描かれているか、あるいは 1 つのパッチに 1 単語が収まっている程度のサイズ。これにより、MaxSim 演算が「ここだ！」という強いピークを検出
   - 平坦化（各パッチ（14×14×3 = 588 個の数値）を、1 列の長いベクトル（588 次元）に並べ替え）
4. 線形射影
   - バッチ化した 588 次元 →Vision Encoder (SigLIP)で 1152 次元 → 線形射影層（学習された重み行列を使用）で 2048 次元
     - SigLIP の世界（1,152 次元）：画像としての特徴（色、形、テクスチャ）で物事を表現する世界
     - Gemma の世界（2,048 次元）: Gemma にとって、テキストの「株」という単語のベクトルと数学的に比較・演算ができる「共通言語」
     - 学習とは 「Vision Encoder が見ている世界（画像特徴）」を、「LLM が理解できる世界（言葉の意味）」へ正確にマッピングできるように、変換行列 $W$ の数値を微調整して "通訳の精度" を極限まで高めること
   - 位置情報（Positional Encoding）を付与
5. 言語モデル（Gemma）による「文脈の復元」
   - 入力： 位置情報が付与された、2,048 次元の「パズルの破片」1,024 個。
   - Gemma の出力は高次元（hidden size）で重いので、ColPali は各パッチ（およびクエリトークン）の出力を D=128 に落とします（論文 4.1）。
   - 出力：これにより、ページは 128 次元 ×1024 本のベクトル集合として保存
     - 論文ではこの保存コストが float16 で 256KB/page と書かれています（B.4）。
6. クエリ側も Gemma でベクトル列にする（“単語ごと”の検索）
   - クエリ（例：「領収書の発行元の会社名」）はテキストなので、Gemma に通して、トークンごとに 128 次元（proj② 後）のベクトル列を作ります。
7. Late Interaction（MaxSim）で「クエリの各語に、最も合うパッチ」を拾う（ColBERT 的”な心臓部）
   - クエリの各トークン i について、ページの全パッチ j との内積を見て、最大のもの（いちばんそれっぽい場所）だけ採用します。そしてそれを全トークンで合計します。
   - ページ内のどこかに「会社名」が小さく載っていても、ページ全体を平均して潰さず、“その単語に対応する局所ピーク”を拾える

- ColPali は **「抽出モデル」ではなく「検索モデル」**なので「会社名を返す」よりもたくさんあるページ（大量の PDF/領収書）の中から 「会社名が書いてある（または会社名に関係する）ページを上位に出す」 のが得意

### ページ検索モデルから「帳票画像から文字の認識品質を予測する予測器」へ

#### 目的

- “特定 OCR エンジンの精度”を予測する
  - ラベル：その OCR エンジンの CER / WER / フィールド抽出正解率
  - メリット：運用に直結（この画像は OCR 通す価値あるか等）
  - デメリット：エンジンが変わると崩れる（ドメイン適合）

#### 動作

- Pooling + LightGBM を用いる

1. PDF レンダリング
   - 画像の縦横サイズに基づいた巨大な行列（テンソル）を作成、各ピクセルに対し、**R（赤）、G（緑）、B（青）**の 3 つのチャネルで「0〜255」の整数値が割り当て
   - 448×448 ピクセルの場合(448, 448, 3)
2. 数値の正規化と整形（SigLIP が計算しやすいように）
   - ColPali が使用する PaliGemma モデルの入力サイズ（例：448×448）に合わせて、画像を拡大または縮小
   - 0〜255 の整数を「0.0〜1.0」の浮動小数点数に変換
   - データセット全体の平均値を引き、標準偏差で割る（色の偏りをなくす）
   - 計算しやすいように軸入れ替え(C, H, W)（色、高さ、幅）に入れ替え
3. パッチ分割
   - 画像を 14×14 ピクセルの小さな「パッチ」に分割（448×448 の画像であれば、縦 32 個 × 横 32 個 ＝ 合計 1024 個のパッチ）
     - 理想的なパッチ：クエリの 1 単語が数パッチにわたって描かれているか、あるいは 1 つのパッチに 1 単語が収まっている程度のサイズ。これにより、MaxSim 演算が「ここだ！」という強いピークを検出
   - 平坦化（各パッチ（14×14×3 = 588 個の数値）を、1 列の長いベクトル（588 次元）に並べ替え）
4. 線形射影
   - バッチ化した 588 次元 →Vision Encoder (SigLIP)で 1152 次元 → 線形射影層（学習された重み行列を使用）で 2048 次元
     - SigLIP の世界（1,152 次元）：画像としての特徴（色、形、テクスチャ）で物事を表現する世界
     - Gemma の世界（2,048 次元）: Gemma にとって、テキストの「株」という単語のベクトルと数学的に比較・演算ができる「共通言語」
     - 学習とは 「Vision Encoder が見ている世界（画像特徴）」を、「LLM が理解できる世界（言葉の意味）」へ正確にマッピングできるように、変換行列 $W$ の数値を微調整して "通訳の精度" を極限まで高めること
   - 位置情報（Positional Encoding）を付与
5. 言語モデル（Gemma）による「文脈の復元」
   - 入力： 位置情報が付与された、2,048 次元の「パズルの破片」1,024 個。
   - Gemma の出力は高次元（hidden size）で重いので、ColPali は各パッチ（およびクエリトークン）の出力を D=128 に落とします（論文 4.1）。
   - 出力：これにより、ページは 128 次元 ×1024 本のベクトル集合として保存
     - 論文ではこの保存コストが float16 で 256KB/page と書かれています（B.4）。

- ここから変更（Retrieval（クエリ・MaxSim）からの変更点）
  - パッチ数：通常 32×32 = 1024（448×448 入力、patch14 相当）
  - 埋め込み次元：
    - 検索用の最終空間：D=128（ColPali が追加した proj② の後）
    - その前（Gemma hidden）：H=2048（品質予測ではこちらが効く可能性もあるので比較候補）

6. パッチ列 → 固定長特徴への集約（Quality 向け Pooling）
   - 目的： 可変長や空間的な広がりを持つパッチ情報（1024×128）を、LightGBM 等が処理できる「固定長の品質特徴ベクトル」に変換する。
     - ここでは「局所的な劣化（汚れ・潰れ）」を希釈させずに捉えるための統計処理を行う。
   - 統計的特徴量の連結
     - Mean Pooling（平均）： 全体的な画質傾向（暗さ、ボケ）を捉える。
     - Max Pooling（最大値）： 特徴空間内で最も強く反応している信号（強いエッジ、極端なノイズ、特異なインク汚れなど）を捉える。
     - Std Pooling（標準偏差）： 情報量のムラ（白紙と文字のコントラスト差、あるいはノイズの散らばり具合）を捉える。
   - 連結ベクトル生成（出力形状： 128×3 = 384 次元）
7. 予測器ヘッドで OCR 認識品質スコアを出力（回帰/分類）
   - 目的： 集約された 384 次元のベクトルから、具体的な OCR 精度（CER/WER）を予測する。
     - 説明変数 (X)： 画像から得た 384 次元の特徴ベクトル。
     - 目的変数 (Y)： 実際の OCR エンジン（Tesseract 等）で計測した正解スコア。
   - 出力：ページ単位（またはフィールド単位）の 予測 OCR 品質
   - （任意）Attention やパッチごとのスコアを持たせる設計にすると、**「どこが悪いせいで品質が落ちそうか」**の可視化まで可能

#### 問題

- ColPali (Contrastive Loss) は、「画質が悪くても、同じドキュメントなら正解とする」ように学習されます。つまり、画質劣化に対して不変（Robust）な特徴量を作ろうとします。
- 対して、OCR 品質予測は画質劣化（ボケ、ノイズ、潰れ）そのものを特徴量として捉える必要があります。

- 128 じゃなくて 2048 の方が良さそう
