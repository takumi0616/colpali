# 研究室の先生のつぶやき「ColPali は OCR の代替となるか」

## Q1

```
Colpaliってocrに使えますか？
```

## A1

```
結論から申し上げますと、ColPaliはOCR（光学文字認識）の代わり、あるいは「OCRを超越した検索手法」として非常に強力に機能します。

正確には、従来のOCRのように「画像をテキストに変換する」プロセスを経ずに、画像（文書のページ全体）から直接その内容を理解して検索できるようにする技術です。

ColPaliがOCRに関連して注目されている理由
従来の文書検索（RAGなど）では、**「PDF → OCRでテキスト抽出 → テキストをベクトル化」**という手順が必要でした。しかし、この方法には「図表や数式、レイアウト情報が消えてしまう」という弱点がありました。

ColPaliは以下の点で、OCRの課題を解決します。

1. 「OCRレス」の検索
ColPaliは、画像そのものを入力として受け取り、視覚的な特徴（文字の形、配置、図、ロゴなど）を直接ベクトル化します。

メリット: OCRエンジンが読み取りに失敗するような複雑なフォントや、位置関係に意味がある表データも、そのままの意味で検索対象にできます。

2. 視覚情報の保持
OCRでは無視されがちな、太字、フォントサイズ、色の違い、図解などの情報を保持したまま検索が可能です。例えば、「赤い文字で書かれた注意書き」といったニュアンスも捉えられる可能性があります。

3. 高速な処理
「OCRをかけてテキストを整形する」という重い前処理をスキップできるため、パイプライン全体を簡略化できる可能性があります（ただし、画像モデルであるため推論時の計算リソースは必要です）。

注意点：テキストの「書き出し」には向かない
ColPaliはあくまで**「検索（Retrieval）」**のためのモデルです。

できること: 「この質問に対する答えが書いてあるページはどこか？」を見つける。

苦手なこと（OCRが必要なケース）: 「この画像に書いてある文字をすべてテキストファイルとして書き出したい」という用途。

もし、最終的にテキストをコピー＆ペーストして利用したいのであれば、ColPaliで対象のページを見つけた後に、GPT-4oやClaude 3.5 Sonnetのような**VLM（視覚言語モデル）**や、従来のOCRエンジンを使ってそのページを読み取るという組み合わせが一般的です。

ColPaliの仕組み（イメージ）
ColPaliは、PaliGemmaという視覚言語モデルをベースにしており、画像をパッチ（断片）に分割して、それぞれのパッチが持つ意味をベクトル化します。これにより、ユーザーの質問テキストと、画像内の特定の場所を高度にマッチングさせることができます。

次のステップとして、以下のようなお手伝いが必要ですか？
ColPaliを実際に試すためのコードやライブラリ（byaldiなど）の紹介。

従来のOCR（Tesseract, Azure AI Document Intelligenceなど）との具体的な性能比較。

ColPaliを使ったRAG（検索拡張生成）システムの構築方法の解説。
```

## Q2

```
Colpaliで得られるLLMに入力される写像は何次元のベクトル空間ですか？
```

## A2

```
ColPaliにおいて、最終的な検索（Retrieval）用のベクトル空間として出力される写像は、128次元のベクトル空間です。ただし、ColPaliは「1ページ＝1つの128次元ベクトル」にするのではなく、1つのページを大量のパッチ（断片）に分割し、その**1つ1つのパッチに対して128次元のベクトルを割り当てる「マルチベクトル（Multi-vector）」**という形式をとっています。具体的な構成は以下の通りです。ベクトル空間の詳細各ベクトルの次元数 ($D$): 128次元1ページあたりのベクトル数: 通常 1,030個内訳: 画像を32x32のグリッドに分割した 1,024個 のパッチトークン + 6個 の特別なテキストトークン（命令文など）。全体の形状 (Shape): (1030, 128)次元の推移プロセスColPaliの内部では、データは以下のように次元を変化させながら処理されます。入力画像: 文書ページを画像として読み込みます。Vision Transformer (ViT): PaliGemmaの内部にあるSigLIP（画像エンコーダー）が画像をパッチに分け、高次元の特徴量として抽出します。LLM (Gemma-2B) 内部: 抽出された画像トークンはLLMの隠れ層の次元（Gemma-2Bの場合は 2,048次元）に投影され、文脈化されます。最終出力 (Projection Layer): LLMの出力に対して線形投影（Linear Projection）が行われ、最終的に軽量な 128次元 の空間へと圧縮されます。なぜ128次元なのか？これはColBERTという検索手法の思想を継承しているためです。効率性: 1ページあたり1,000個以上のベクトルを保持するため、1つ1つの次元が高いとメモリ消費量が膨大になります。128次元に抑えることで、検索精度を維持しつつストレージ容量を節約しています。Late Interaction（遅延交差）: 検索時には、クエリの各トークン（128次元）と、画像内の全パッチ（128次元 × 1,030個）の間で総当たり的な計算（MaxSim演算）を行い、最も関連性の高い場所を特定します。補足: 最新のモデル（ColQwen2など）でも、基本的なマルチベクトルの構造や128次元という設定は広く採用されています。さらに詳しく知りたい情報はありますか？ColPaliの128次元ベクトルをさらに圧縮する技術（バイナリ量子化など）について。この128次元ベクトルを使ってどのように「検索」が行われるかの計算アルゴリズム。ColQwen2など、他のVLMベースモデルとの次元数の違い。
```

## Q3

```
バイナリ量子化について、量子化しても問題ないのですか？
```

## A3

```
バイナリ量子化（Binary Quantization）をColPaliに適用しても問題ないかという点については、**「そのままでは精度が落ちるが、『リランキング（再評価）』と組み合わせることで、実用上ほとんど問題ないレベルで運用できる」**というのが最新の技術的な回答です。単にデータを1ビットにするだけでなく、賢い運用方法がセットになっています。1. なぜ「問題ない」と言えるのか？（工夫の仕組み）バイナリ量子化は、32ビット（float32）の数値を「正なら1、負なら0」の1ビットに圧縮します。情報量は32分の1になりますが、以下の手法を組み合わせることで精度を維持します。オーバーサンプリング（多めに取ってくる）:検索時に、最終的に欲しい数（例：Top 10）よりも多めの候補（例：Top 50）をバイナリベクトルで高速にざっくりと抽出します。リランキング（精緻な再計算）:抽出された50個に対してのみ、元のフル精度（float32やbfloat16）のベクトルを使って計算し直します。これにより、最終的なTop 10の精度はフル精度の時とほぼ変わらないレベル（95%以上の再現率など）に保てます。2. メリットとデメリットの比較項目フル精度 (float32)バイナリ量子化 (+リランキング)メモリ使用量非常に大きい (100%)劇的に小さい (約3%)検索速度低速（浮動小数点演算）超高速（ビット演算）精度 (Recall)100% (基準)90%〜98% 程度 (設定次第)ストレージ高コスト低コスト3. ColPaliにおける特有の事情ColPaliは「1ページ＝1,000個以上のベクトル」を持つため、数万ページのドキュメントを扱うとメモリ消費が爆発します。そのため、**現実的な大規模運用ではバイナリ量子化は「ほぼ必須」**の技術とみなされています。VespaやQdrantといった最新のベクトルデータベースでも、ColPaliとバイナリ量子化を組み合わせた最適化が公式に推奨されています。結論「検索速度とコストを優先したい」のであれば、バイナリ量子化は非常に優れた選択肢です。 ただし、単に1ビットにするだけだと「似たようなページ」の区別がつかなくなるため、必ず**「バイナリで高速検索 → 上位をフル精度でリランキング」**という2段構えの構成にすることをお勧めします。次に、具体的な実装やツールについて知りたいことはありますか？バイナリ量子化をサポートしているベクトルデータベース（Qdrant, Vespa, Azure AI Search等）の具体的な設定方法。リランキングを行う際の「オーバーサンプリング数」をどう決めるべきか。量子化を導入するためのPythonコード例（byaldiなどのライブラリ使用時）。
```

## Q4

```
帳票画像から文字の認識品質を予測する予測器を構築したいと思っています。
このcolpaliから得られる特徴ベクトルを使うメリット、デメリット。
方法を教えてください。
```

## A4

```
帳票（フォーム）の文字認識品質（OCR精度）を予測するというタスクにおいて、ColPaliの特徴ベクトルを活用するのは非常に鋭いアプローチです。

ColPaliは「文字の形」だけでなく、「文字の配置（レイアウト）」「背景のノイズ（スキャン汚れや網掛け）」「フォントの鮮明さ」といった、OCRの品質を左右する視覚的要因を128次元の空間に凝縮しているからです。

1. ColPaliを使うメリット・デメリット
メリット
レイアウト依存の劣化を捉えられる: 帳票特有の「罫線と文字が重なっている」「網掛けで見にくい」といった、文字単体ではなく周辺状況に起因する認識ミスを予測しやすいです。

エンドツーエンドの視覚特徴: 画像処理の専門知識（コントラストの計算、ノイズの統計量など）を組み合わせて特徴量エンジニアリングをする必要がなく、モデルが自動的に重要な視覚特徴を抽出してくれます。

マルチモーダルな理解: 「この場所は住所欄だから難しい（手書きの可能性がある）」といった、文書の構造的な文脈もベクトルに含まれます。

デメリット
計算コスト: 単純な画像統計量（輝度の分散など）を計算するのに比べると、VLM（PaliGemma）を動かすためのGPUリソースが必要です。

局所情報の希釈: ページ全体のベクトル（1,030個）を扱うため、非常に小さな1文字だけの欠けを予測したい場合には、情報が広範囲に分散しすぎていて学習が難しいことがあります。

2. 構築方法のステップ
認識品質（例：CER（文字誤り率）や自信度スコア）を目的変数とする回帰モデル、または「認識成功/失敗」の二値分類モデルを構築する流れです。

Step 1: データセットの準備
入力: 帳票の画像。

正解ラベル: OCRエンジン（Tesseract, Google Cloud Visionなど）を通した結果の「認識精度スコア」や、正解テキストとの「編集距離（一致度）」。

Step 2: ColPaliによる特徴量抽出
ColPali（またはそのバックボーンのPaliGemma）に画像を入力し、LLMの最終層から得られる**マルチベクトル（1,030トークン × 128次元）**を取得します。

Step 3: 予測器の設計
1,030個のベクトルをどう扱うかがポイントです。

Pooling法: 1,030個のベクトルを平均（Mean Pooling）または最大値（Max Pooling）で集約し、1つの128次元ベクトルにしてから、軽量なモデル（LightGBMやSVR）に入力する。

Attention法: 1,030個のトークンをそのまま入力として、小さなTransformer層や1D-CNNを通し、画像内の「どこが原因で品質が落ちているか」を特定させながら学習する。

3. 具体的な実装のアドバイス
もし私が構築するのであれば、まずは**「平均プーリング + LightGBM」**から始めます。

理由: 1,030個のベクトルをそのまま扱うと次元が多すぎて過学習しやすいため、まずはページ全体の「見映え」を128次元に凝縮して、大まかな品質（スキャンがボケているか、全体的に複雑なレイアウトか）を判定させるのが効率的だからです。

Tips: 帳票の特定の「項目（氏名欄、金額欄など）」ごとに品質を予測したい場合は、その項目がある座標に対応するパッチ（1,030個のうちの特定範囲のベクトル）だけを切り出して入力に使うと、非常に精度の高いピンポイントな予測器になります。

次のステップとして、どのような情報を深掘りしましょうか？
特定の座標（OCRの読取範囲）に絞って特徴量を抽出する具体的な実装コード。

ColPaliの出力をLightGBMに繋ぐためのデータ整形パイプラインの作り方。

「認識品質」として定義すべき指標（CER, WER, 信頼度など）の選び方。
```

## Q5

```
帳票画像認識における精度判定タスクの高度化：DiT由来の大域的埋め込みからColPaliによる遅延相互作用型検証モデルへのパラダイムシフト
```

## A5

```
1. 序論：ドキュメントインテリジェンスにおける表現学習の課題1.1 背景：End-to-Endドキュメント理解への移行と信頼性評価の重要性近年、企業活動におけるデジタルトランスフォーメーション（DX）の加速に伴い、帳票処理の自動化技術、いわゆるドキュメントインテリジェンス（Document Intelligence）の需要は急速に拡大しています。従来のOCR（光学文字認識）エンジンと後処理としてのルールベースNLP（自然言語処理）を組み合わせたパイプライン型のアプローチから、画像とテキストを包括的に理解するVision-Language Model（VLM）を用いたEnd-to-Endのアプローチへと技術的な重心が移行しつつあります。この流れの中で、自動化システムの信頼性を担保するために不可欠となるのが、「認識結果が正しいかどうか」を判定するタスク、すなわち信頼度推定（Confidence Estimation）または精度予測（Accuracy Prediction）です。ユーザーが現在取り組んでいる、入力された帳票画像データからその認識精度を判定するDNN（Deep Neural Network）の構築は、まさにこの信頼性担保の中核をなす技術課題です。特に、Diffusion Transformer（DiT）を用いた埋め込み空間からの予測というアプローチは、生成AIの隆盛を受けた最先端の試みであり、画像生成モデルが獲得した強力な表現能力を認識タスクに転用しようとする野心的な取り組みと言えます。1.2 問題の所在：DiT埋め込みにおける意味的崩壊しかしながら、ユーザーが直面している「会社番号のような数字列は予測できるが、会社名や店舗名はまったく当たらない」という現象は、現在の画像表現学習における根本的な課題、すなわち「大域的埋め込み（Global Embedding）における情報ボトルネック」と「生成モデルの潜在空間の特性」を浮き彫りにしています。DiTは本来、画像の分布を学習し、ノイズから画像を再構成するために設計された生成モデルです。その潜在空間（Latent Space）は、画像の連続的な変化を滑らかに表現することに適しています。数字列のような、視覚的にも意味的にもエントロピーが高く、局所的な特徴が全体を決定づけるデータに対しては、ある程度の識別能力を発揮します。しかし、会社名や店舗名といった、高度な意味的コンテキストと視覚的スタイル（フォント、ロゴ、配置）が混在し、かつ微細な差異（例えば「株式会社」の有無や、類似した店舗名の区別）が重要となるエンティティに対しては、画像を単一のベクトルに圧縮する過程で決定的な情報損失が発生します。これを「表現の崩壊（Representation Collapse）」と呼びます。1.3 本報告書の目的と構成本報告書では、この問題に対する解決策として、「ColPali: Efficient Document Retrieval with Vision Language Models」1 で提案されたアーキテクチャと概念を導入することを提案します。ColPaliは、画像を単一のベクトルに圧縮するのではなく、多数の画像パッチ埋め込みとして保持し、クエリ（テキスト）との照合時に初めて相互作用させる「遅延相互作用（Late Interaction）」メカニズムを採用しています。本稿では、まずDiTベースのアプローチがなぜ固有名詞の精度判定に失敗するのかを理論的に分析します。次に、ColPaliのアーキテクチャがいかにしてこの問題を解決するかを詳述し、ユーザーのタスクである「認識精度の判定」に特化した具体的なシステム構成と実装戦略を提案します。これは単なるモデルの置き換えではなく、ドキュメントの「読み取り」から「視覚的照合」へのパラダイムシフトを意味します。2. 理論的分析：なぜDiTとコサイン類似度は固有名詞に失敗するのかユーザーが観測した「数字はうまくいくが、名前はうまくいかない」という現象は、偶発的なものではなく、採用されたアーキテクチャ（DiT + 大域的埋め込み）と評価指標（コサイン類似度）の数理的特性に起因する必然的な結果です。2.1 生成モデル（DiT）の潜在空間と識別タスクの不整合Diffusion Transformer（DiT）は、画像生成において卓越した性能を示しますが、その学習目的は「データ分布の尤度最大化」です。これは、潜在空間において類似した画像（例えば「領収書」と「請求書」）を近くに配置し、その間を滑らかに補間できるように空間を構成することを意味します。2.1.1 平滑化された潜在空間の弊害生成モデルにとって、潜在空間の「滑らかさ」は重要です。しかし、識別タスク、特に「正解の文字列か否か」を判定するタスクにおいては、この滑らかさが仇となります。数字列の場合（成功の理由）： 数字列（例：「123-4567」）は、純粋に記号的な配列であり、視覚的な形状がその意味を完全に決定します。DiTの強力な注意機構は、この明確な視覚的特徴（エッジの並び）を捉え、潜在空間内の特定の領域にマッピングすることができます。数字列には「文脈的な同義語」が存在しないため、潜在空間での位置は比較的孤立しており、予測が容易です。会社名・店舗名の場合（失敗の理由）： 固有名詞は、視覚情報だけでなく、強い意味的（セマンティック）な情報を持ちます。例えば、「Amazon」という文字は、単なる文字の羅列ではなく、「巨大IT企業」「ECサイト」といった概念と結びついています。DiTが大域的なプーリング（Global Pooling）を行って画像を単一のベクトルに圧縮する際、これらの「概念的な情報」が支配的になります。その結果、画像が「あるテクノロジー企業の領収書」というクラスターには分類されても、「Amazon Web Services」なのか「Amazon Japan」なのかといった微細な文字レベルの識別情報は、ベクトルの次元圧縮によって消失してしまいます 3。2.2 大域的埋め込み（Global Embedding）の情報ボトルネック現在のシステムでは、画像全体（あるいは切り出し画像）を一つのベクトル $\mathbf{v}_{img}$ に変換し、それを正解テキストの埋め込み $\mathbf{v}_{text}$ と比較していると推察されます。2.2.1 意味の「平均化」による情報の喪失単一ベクトル表現（Dense Retrievalモデルなど）は、入力された全ての情報を固定長の次元（例えば1024次元）に押し込みます。現象： 「株式会社三菱UFJ銀行」という画像を入力した場合、ベクトルには「銀行」「金融機関」「赤色のロゴ」「明朝体」といった特徴が混然一体となって記録されます。結果： これに対し、「株式会社三井住友銀行」というテキストとのコサイン類似度を計算すると、両者は「銀行」「金融」「日本の企業」という共通項を多く持つため、ベクトル空間上では非常に近い位置に存在することになります。コサイン類似度は $0.85$ 以上の高い値を示すでしょう。しかし、精度の判定（Verification）タスクにおいては、この両者は「別物（不正解）」として扱われなければなりません。単一ベクトル表現では、この「微細だが決定的な違い」を表現するだけの解像度が不足しているのです 4。2.3 コサイン類似度の限界：高次元空間における集中現象高次元ベクトル空間において、意味的に関連するエンティティ同士のコサイン類似度は、しばしば非常に狭い範囲に集中します（Concentration of Measure）。特にDiTのようなモデルでは、ドキュメント画像というモダリティの共通性が強いため、どの会社名の画像であっても、ある程度高い類似度が出てしまいます。これを「正解率」のプロキシとして使うと、閾値の設定が極めて困難になります。正しいペアの類似度が0.92、間違ったペア（しかし同じ業種の会社）の類似度が0.91となると、ノイズの影響で逆転現象が頻発し、「まったく当たらない」という結果を招きます。3. 解法パラダイム：ColPali（Contextualized Late Interaction over PaliGemma）この行き詰まりを打破するために提案するのが、ColPali の導入です。ColPaliは、画像を無理やり一つのベクトルに押し込めることをやめ、「パッチ（画像の小領域）」ごとの埋め込みベクトルをそのまま保持し、照合時にそれらをフル活用するアプローチをとります。3.1 ColPaliのアーキテクチャ概要ColPaliは、GoogleのVision-Language Modelである PaliGemma をベースに、スタンフォード大学が開発した検索モデル ColBERT の相互作用メカニズムを組み込んだものです 1。コンポーネント概要役割Vision EncoderSigLIP-So400m (Vision Transformer)画像を $14 \times 14$ ピクセルのパッチに分割し、それぞれのパッチを文脈化された特徴ベクトルに変換する。Language ModelGemma-2B (Decoder LLM)テキスト（クエリ）をトークン化し、それぞれのトークンを埋め込みベクトルに変換する。Projection LayerLinear Projection視覚特徴を言語モデルの埋め込み空間（128次元等）に射影し、画像とテキストを同一空間で比較可能にする。InteractionMaxSim (Late Interaction)全てのクエリトークンと全ての画像パッチの間で総当たり的に類似度を計算し、最大値を合計する。3.2 なぜColPaliが「会社名」の問題を解決するのかColPaliの核心は、マルチベクトル表現（Multi-Vector Representation） にあります。3.2.1 局所性の保存とトークンレベルの照合DiTのアプローチが画像を「スープのように混ぜ合わせる」のに対し、ColPaliは画像を「モザイク画」として扱います。具体例： 「Amazon」という会社名の画像をColPaliに入力すると、およそ1024個（$32 \times 32$ グリッド）のベクトルが出力されます。その中には、「A」の形状を持つパッチ、「ma」の形状を持つパッチ、「zon」の形状を持つパッチが、それぞれの位置情報を保持したまま独立したベクトルとして存在します。照合プロセス： ユーザーが「Amazon」というテキストが正しいか検証したい場合、システムはテキストを [A, ma, zon] のようにトークン化します。そして、トークン A のベクトルは、画像の全パッチの中から最も A に似ているパッチを探しに行きます。同様に zon も自分のパートナーを探します。効果： 背景にどんなノイズがあろうと、あるいは隣に別の文字があろうと、それぞれのトークンが対応する視覚的証拠（Visual Evidence）を個別に見つけ出すことができます。これにより、グローバルな意味情報に惑わされることなく、「そこにその文字パターンが存在するか」 という物理的・視覚的な事実に基づいてスコアを算出できます 7。3.2.2 抽象的字句マッチング（Abstract Lexical Matching）ColPaliが行っているのは、厳密なOCR（文字コードへの変換）ではありません。抽象的字句マッチング と呼ばれる、より柔軟なプロセスです。モデルは、「"Amazon"というテキストトークンの埋め込み」と「"Amazon"という画像パッチの埋め込み」が、ベクトル空間上で近くなるように学習されています。これにより、OCRが誤読しやすいような掠れた文字や特殊なフォントであっても、視覚的な特徴が意味的に合致していれば高いスコアを出せます。これは、OCRの出力結果に依存せずに精度を判定したいというユーザーの目的に完全に合致します 9。4. 提案手法：ColPaliを用いた認識精度判定システムの構築DiTを廃止し、ColPaliを用いた新しい精度判定パイプラインを提案します。このシステムは、入力された「画像」と、認識結果（あるいは正解候補）である「テキスト」の整合性を、ColPaliのLate Interactionスコアを用いて定量化します。4.1 システムアーキテクチャ4.1.1 入力データ帳票画像（$I$）： 認識対象となる領域のクロップ画像、または帳票全体の画像。仮説テキスト（$T$）： OCRエンジンが出力したテキスト、あるいはユーザーが検証したい正解テキスト（会社名など）。4.1.2 処理フロー視覚エンコーディング（Visual Encoding）：画像 $I$ をPaliGemmaのVision Encoder（SigLIP）に入力します。出力はプーリングせず、パッチ単位の埋め込みシーケンス $E_{img} = \{v_1, v_2,..., v_M\}$ を取得します。ここで $M$ はパッチ数（例：1024）、各ベクトル $v_i$ は $D$ 次元（例：128次元）です。重要： ここで得られた $E_{img}$ が、画像の「情報ロスなし」の表現です。テキストエンコーディング（Text Encoding）：仮説テキスト $T$ をColPaliのTokenizerでトークン化し、埋め込みシーケンス $E_{text} = \{t_1, t_2,..., t_N\}$ を得ます。$N$ はトークン数です。遅延相互作用スコアリング（MaxSim Calculation）：このステップが判定の核となります。テキストの各トークン $t_i$ について、画像パッチ全体との最大類似度を計算し、それらを総和します。$$S_{raw} = \sum_{i=1}^{N} \max_{j=1}^{M} (t_i \cdot v_j)$$この $S_{raw}$ は、「テキスト内の全ての部分文字列について、画像内に視覚的根拠がどれだけ強く存在するか」を示しています 8。スコアの正規化と確率への変換（Calibration）：$S_{raw}$ はトークン数 $N$ に依存して大きくなるため、そのままでは「精度」として扱えません。これを正規化します。4.2 実装戦略詳細4.2.1 画像解像度とタイリング戦略会社名や店舗名は帳票内では小さな領域に書かれていることが多いです。PaliGemmaの標準入力解像度（例えば $448 \times 448$）に帳票全体をリサイズして入力すると、文字がつぶれてパッチ情報が失われる可能性があります。クロップ入力の推奨： もしDNNの前段で検出（Detection）ができているなら、会社名領域を切り出し、アスペクト比を維持したままパディングして入力することを強く推奨します。動的タイリング（Dynamic Tiling）： 帳票全体を入力する必要がある場合、画像を複数のタイルに分割してエンコードし、パッチのバッグ（Bag of Patches）を結合する手法が有効です 11。4.2.2 クエリプロンプトの設計ColPaliはVLMであるため、テキストエンコーダーへの入力にはプロンプトが必要です。学習時の形式： <image> Describe the image.検証時の形式： 単に会社名を入力するだけでなく、文脈を与えることが有効な場合がありますが、ColPaliの検索タスクでのファインチューニングの性質上、単語（会社名）のみ、あるいは Question: Company Name? Answer: [会社名] のような形式でエンコードすることで、より特異的な埋め込みが得られる可能性があります。実験的には、OCR結果のテキストそのものをクエリとして投げるのが最もシンプルかつ強力です。4.2.3 スコアの正規化手法（Confidence Calibration）ユーザーの目的は「判定」ですので、0〜1の確率値が必要です。MaxSimスコアは上限がありません。トークン平均化： まず、総和をトークン数で割ります。$$S_{norm} = \frac{1}{N} \sum_{i=1}^{N} \max_{j=1}^{M} (t_i \cdot v_j)$$これにより、文字列の長さに関わらず「平均的なマッチング度合い」が得られます。ロジスティック回帰（Platt Scaling）： 検証用データセット（画像と、正しいテキスト/誤ったテキストのペア）を用意し、$S_{norm}$ を入力として正誤（1/0）を予測する単純なロジスティック回帰モデルを学習させます。$$P(Correct) = \sigma(w \cdot S_{norm} + b)$$これにより、MaxSimスコアが、例えば「0.7以上なら95%の確率で合っている」といった解釈可能な信頼度スコアに変換されます 13。5. 実験的考察と最適化：実用化に向けた知見5.1 なぜ「数字」と「名前」で差が出るのか：再考DiTアプローチでの失敗原因を深掘りすると、「統語的密度（Syntactic Density）」と「意味的密度（Semantic Density）」 の違いに行き着きます。数字列： 統語的密度が高い（記号の並び順が全て）。意味的密度は低い（数字の羅列に文脈はない）。DiTはこの「形状のパターン」をテクスチャとして学習できた可能性があります。会社名： 意味的密度が極めて高い。DiTの潜在空間では「意味」が支配的になり、「形状（個々の文字）」の情報が抑制されます。ColPaliは、パッチ単位で情報を保持することで、意味情報（VLMの知識）と形状情報（SigLIPの視覚特徴）の両方を維持し、このジレンマを解消します。5.2 バイナリ量子化（Binary Quantization）による軽量化ColPaliの欠点は、画像1枚あたり数千個のベクトルを保持するため、メモリ消費量が大きいことです（DiTの単一ベクトルに比べて約1000倍）。しかし、最新の研究 15 によれば、ColPaliの埋め込みベクトルは バイナリ量子化（float32 -> int1） しても性能がほとんど劣化しません。提案： 実運用時は、パッチ埋め込みを1ビット化してください。これによりストレージとメモリ帯域を32倍削減でき、検索・照合速度が劇的に向上します。ユーザーのタスクは大規模検索ではなく「1対1検証（Verification）」に近いと思われるため、オンメモリで処理する分には量子化なしでも十分高速（数ミリ秒〜数十ミリ秒）ですが、将来的なスケーラビリティのために量子化は有効な選択肢です。5.3 日本語対応とファインチューニングColPali（PaliGemma）は多言語能力を持っていますが、学習データ（ViDoReベンチマーク）は英語が中心です。日本の帳票特有のフォント、縦書き、漢字の異体字などに対応するためには、LoRA（Low-Rank Adaptation） を用いたファインチューニングが推奨されます。学習データ： 日本語の帳票画像と、その中のテキスト（会社名など）のペア。損失関数： 肯定ペア（正しい画像とテキスト）のMaxSimスコアを高く、否定ペア（正しい画像と、一文字違いのテキストなど）のスコアを低くする対照学習（Contrastive Loss）を用います。特に、ハードネガティブ（難易度の高い誤答） を含めることで、モデルは「大まかな意味」ではなく「正確な文字の視覚情報」を見るように強制されます 17。5.4 比較：他手法との優位性特徴DiT / Dense EmbeddingColPali (Late Interaction)LayoutLM / Donut表現形式単一ベクトル (Global)パッチごとの多重ベクトル (Local)トークン列生成 (Autoregressive)会社名認識× (意味空間で埋没)◎ (トークン単位で視覚照合)△ (OCR精度に依存/ハルシネーションのリスク)処理速度高速 (内積1回)中速 (行列演算)低速 (トークン数分生成が必要)解釈性低 (ブラックボックス)高 (どのパッチが反応したか可視化可能)中 (Attention Map)ColPaliの特筆すべき利点は**解釈性（Interpretability）**です。MaxSimの計算過程で、「テキストのどの文字が、画像のどのパッチとマッチしたか」をヒートマップとして可視化できます。これにより、「会社名の最初の3文字は合っているが、末尾の『支店』が見つからない」といった診断が可能になり、ユーザーのデバッグ作業を大幅に支援します 11。6. 結論：視覚的意味照合への転換ユーザーが直面している「会社名や店舗名が当たらない」という問題は、DiTを用いた大域的埋め込み手法が持つ構造的な限界に起因します。生成モデルの滑らかな潜在空間と、単一ベクトルへの情報圧縮は、固有名詞のような微細な識別情報を保持するのには不向きです。本報告書で提案した ColPaliアーキテクチャ は、この問題を「解像度」と「相互作用」の観点から根本的に解決します。情報の保存： 画像を圧縮せず、パッチ群として保持することで、微細な文字情報やロゴ情報を損失なく扱います。遅延相互作用： テキストトークンと画像パッチを直接対話させることで、意味的な類似性だけでなく、物理的な視覚的一致（Visual Grounding）をスコアに反映させます。スケーラブルな検証： MaxSimスコアを正規化・較正することで、信頼性の高い「精度判定スコア」を算出できます。ユーザーへの具体的なアクションプランとしては、まず colpali-engine を導入し、手持ちのデータセットに対して事前学習済みモデル（vidore/colpali-v1.2 等）を用いたMaxSimスコアの分布を確認することから始めることを推奨します。数字だけでなく、会社名においても、正解テキストとのスコアが不正解テキストよりも有意に高くなることが確認できるはずです。これは、帳票認識AIの評価系を、不確実な回帰予測から、堅牢な視覚的エビデンスに基づく照合へと進化させる重要なステップとなるでしょう。表1：データタイプ別アプローチ比較と推奨事項データタイプ特性DiT/Global Embedding (現状)ColPali/Late Interaction (提案)推奨アクション会社番号統語的・定型的・低エントロピー〇 動作する形状が単純でユニークなため、大域的特徴で捉えられる。◎ 動作する個々の数字パッチとの照合により、さらに堅牢になる。どちらでも良いが、システム統一のためにColPaliへ移行推奨。会社名・店舗名意味的・可変長・高エントロピー× 失敗する意味空間での近接性により、類似企業と区別不能になる。◎ 動作するトークンごとの視覚照合により、一文字の違いも検出可能。ColPaliへの移行が必須。住所・品目混合的・長文△ 不安定長い文字列はベクトル内で情報が希釈される。◎ 動作する長いシーケンスでもトークン単位で照合するため精度が落ちない。ColPaliが圧倒的に有利。図解概念：MaxSimによるスコアリングメカニズム（テキストでの説明）クエリ：「三」「菱」「商」「事」　　　　↓　　↓　　↓　　↓画像パッチ群（1024個）に対して、それぞれが「一番似ているパッチ」を探す。「三」は画像の座標(x1, y1)にある「三」のパッチと強く反応 (Score: 25.0)「菱」は画像の座標(x1, y2)にある「菱」のパッチと強く反応 (Score: 24.5)...合計スコアが高い ＝ 画像の中に全ての文字の視覚的証拠が存在する ＝ 認識精度が高いこのメカニズムにより、DiTでは不可能だった「名前の検証」が可能になります。
```
