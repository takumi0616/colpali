"""
ColPali - ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡ºã®ãƒ‡ãƒ¢ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ç”»åƒã‹ã‚‰ColPaliã‚’é€šã—ã¦ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ128æ¬¡å…ƒÃ—Nãƒˆãƒ¼ã‚¯ãƒ³ ã¾ãŸã¯ 2,048æ¬¡å…ƒÃ—Nãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’
å–å¾—ã™ã‚‹ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
"""

import torch
from PIL import Image
from typing import Literal, Tuple
import argparse
from pathlib import Path

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from modeling_colpali import ColPali
from processing_colpali import ColPaliProcessor


def get_embeddings(
    model: ColPali,
    processor: ColPaliProcessor,
    images: list[Image.Image],
    embedding_type: Literal["128dim", "2048dim"] = "128dim",
    device: str = "auto"
) -> Tuple[torch.Tensor, dict]:
    """
    ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
    
    Args:
        model: ColPaliãƒ¢ãƒ‡ãƒ«
        processor: ColPaliãƒ—ãƒ­ã‚»ãƒƒã‚µ
        images: PILç”»åƒã®ãƒªã‚¹ãƒˆ
        embedding_type: "128dim" (æ¤œç´¢ç”¨) ã¾ãŸã¯ "2048dim" (Gemmaã®ä¸–ç•Œ)
        device: ãƒ‡ãƒã‚¤ã‚¹ ("auto", "cuda", "mps", "cpu")
    
    Returns:
        embeddings: ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ (batch_size, N_tokens, dim)
        info: æƒ…å ±è¾æ›¸ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€æ¬¡å…ƒæ•°ãªã©ï¼‰
    """
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if device == "auto":
        if torch.cuda.is_available():
            device = "cuda:0"
        elif torch.backends.mps.is_available():
            device = "mps"
        else:
            device = "cpu"
    
    model = model.to(device)
    model.eval()
    
    # ç”»åƒã‚’å‡¦ç†
    batch_images = processor.process_images(images).to(device)
    
    # Forward pass
    with torch.no_grad():
        if embedding_type == "2048dim":
            # Gemmaã®2,048æ¬¡å…ƒã‚’å–å¾—ï¼ˆprojå‰ï¼‰
            outputs = model.model(
                **batch_images,
                output_hidden_states=True
            )
            embeddings = outputs.hidden_states[-1]  # (batch_size, N_tokens, 2048)
            
            # ãƒã‚¹ã‚­ãƒ³ã‚°é©ç”¨
            attention_mask = batch_images["attention_mask"].unsqueeze(-1)
            embeddings = embeddings * attention_mask
            
        else:  # "128dim"
            # é€šå¸¸ã®ColPaliå‡ºåŠ›ï¼ˆ128æ¬¡å…ƒï¼‰
            embeddings = model(**batch_images)  # (batch_size, N_tokens, 128)
    
    # æƒ…å ±ã‚’åé›†
    batch_size, n_tokens, dim = embeddings.shape
    info = {
        "batch_size": batch_size,
        "n_tokens": n_tokens,
        "embedding_dim": dim,
        "device": device,
        "embedding_type": embedding_type
    }
    
    return embeddings, info


def apply_pooling(
    embeddings: torch.Tensor,
    method: Literal["mean", "max", "std", "concat"] = "mean"
) -> torch.Tensor:
    """
    ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã—ã¦å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
    
    Args:
        embeddings: ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ« (batch_size, N_tokens, dim)
        method: ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•
            - "mean": å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "max": æœ€å¤§å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "std": æ¨™æº–åå·®ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "concat": Mean + Max + Std ã‚’é€£çµï¼ˆ3å€ã®æ¬¡å…ƒï¼‰
    
    Returns:
        pooled: å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ« (batch_size, dim) ã¾ãŸã¯ (batch_size, dim*3)
    """
    if method == "mean":
        return embeddings.mean(dim=1)  # (batch_size, dim)
    
    elif method == "max":
        return embeddings.max(dim=1)[0]  # (batch_size, dim)
    
    elif method == "std":
        return embeddings.std(dim=1)  # (batch_size, dim)
    
    elif method == "concat":
        mean_pool = embeddings.mean(dim=1)
        max_pool = embeddings.max(dim=1)[0]
        std_pool = embeddings.std(dim=1)
        return torch.cat([mean_pool, max_pool, std_pool], dim=-1)  # (batch_size, dim*3)
    
    else:
        raise ValueError(f"Unknown pooling method: {method}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="ColPali - ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º")
    parser.add_argument(
        "--image",
        type=str,
        required=True,
        help="å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--model-name",
        type=str,
        default="vidore/colpali-v1.2",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆHuggingFaceï¼‰"
    )
    parser.add_argument(
        "--embedding-type",
        type=str,
        choices=["128dim", "2048dim"],
        default="128dim",
        help="åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒ: 128dim (æ¤œç´¢ç”¨) ã¾ãŸã¯ 2048dim (Gemmaã®ä¸–ç•Œ)"
    )
    parser.add_argument(
        "--pooling",
        type=str,
        choices=["none", "mean", "max", "std", "concat"],
        default="none",
        help="ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="ãƒ‡ãƒã‚¤ã‚¹ (auto, cuda, mps, cpu)"
    )
    
    args = parser.parse_args()
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    print(f"ğŸ“¸ ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­: {args.image}")
    image_path = Path(args.image)
    if not image_path.exists():
        raise FileNotFoundError(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.image}")
    
    image = Image.open(image_path).convert("RGB")
    print(f"   ç”»åƒã‚µã‚¤ã‚º: {image.size}")
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰
    print(f"\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {args.model_name}")
    model = ColPali.from_pretrained(
        args.model_name,
        torch_dtype=torch.bfloat16,
    )
    processor = ColPaliProcessor.from_pretrained(args.model_name)
    print("   âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    
    # åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
    print(f"\nğŸ”„ {args.embedding_type} åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ä¸­...")
    embeddings, info = get_embeddings(
        model=model,
        processor=processor,
        images=[image],
        embedding_type=args.embedding_type,
        device=args.device
    )
    
    print(f"\nğŸ“Š ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æƒ…å ±:")
    print(f"   - ãƒãƒƒãƒã‚µã‚¤ã‚º: {info['batch_size']}")
    print(f"   - ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {info['n_tokens']}")
    print(f"   - åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {info['embedding_dim']}")
    print(f"   - ãƒ‡ãƒã‚¤ã‚¹: {info['device']}")
    print(f"   - shape: {tuple(embeddings.shape)}")
    
    # ãƒ—ãƒ¼ãƒªãƒ³ã‚°é©ç”¨
    if args.pooling != "none":
        print(f"\nğŸ¯ {args.pooling.upper()} ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’é©ç”¨ä¸­...")
        pooled = apply_pooling(embeddings, method=args.pooling)
        print(f"   å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ« shape: {tuple(pooled.shape)}")
        
        print(f"\nâœ… å®Œäº†ï¼")
        print(f"\nğŸ’¡ ä½¿ç”¨ä¾‹:")
        print(f"   ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’LightGBMã‚„SVRã«å…¥åŠ›ã—ã¦ã€OCRå“è³ªäºˆæ¸¬ãŒå¯èƒ½ã§ã™ã€‚")
        print(f"   ä¾‹: pooled_vector.cpu().numpy() â†’ shape: {tuple(pooled.cpu().numpy().shape)}")
    else:
        print(f"\nâœ… å®Œäº†ï¼")
        print(f"\nğŸ’¡ ä½¿ç”¨ä¾‹:")
        print(f"   1. Late Interaction (MaxSim) ã§æ¤œç´¢ã«ä½¿ç”¨")
        print(f"   2. Poolingã‚’é©ç”¨ã—ã¦å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›")


if __name__ == "__main__":
    main()
