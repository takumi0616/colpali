"""
ColPali - ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡ºã®ãƒ‡ãƒ¢ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ç”»åƒã‹ã‚‰ColPaliã‚’é€šã—ã¦ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ128æ¬¡å…ƒÃ—Nãƒˆãƒ¼ã‚¯ãƒ³ ã¾ãŸã¯ 2,048æ¬¡å…ƒÃ—Nãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’
å–å¾—ã™ã‚‹ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

æ›´æ–° (2026/01/04):
- transformersã®ãƒã‚¤ãƒ†ã‚£ãƒ–å®Ÿè£… (ColPaliForRetrieval) ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
- ãƒ¢ãƒ‡ãƒ«åã‚’ vidore/colpali-v1.3-hf ã«å¤‰æ›´ï¼ˆ-hfã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒtransformersãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆï¼‰
"""

import os
import torch
from PIL import Image
from typing import Literal, Tuple
import argparse
from pathlib import Path

# HuggingFaceèªè¨¼ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿è¾¼ã‚€ï¼‰
def setup_hf_auth():
    """HuggingFaceã®èªè¨¼ã‚’è¨­å®š"""
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰HF_TOKENã‚’èª­ã¿è¾¼ã‚€
    env_path = Path(__file__).parent.parent / ".env"
    if env_path.exists():
        with open(env_path, "r") as f:
            for line in f:
                if line.startswith("HF_TOKEN="):
                    token = line.strip().split("=", 1)[1]
                    os.environ["HF_TOKEN"] = token
                    os.environ["HUGGINGFACE_HUB_TOKEN"] = token
                    print(f"   âœ… HF_TOKENã‚’.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    return token
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    token = os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACE_HUB_TOKEN")
    if token:
        print(f"   âœ… HF_TOKENã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return token
    
    print("   âš ï¸ HF_TOKENãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚huggingface-cli loginã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
    return None


def get_embeddings(
    model,
    processor,
    images: list[Image.Image],
    embedding_type: Literal["128dim", "2048dim"] = "128dim",
    device: str = "auto"
) -> Tuple[torch.Tensor, dict]:
    """
    ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
    
    Args:
        model: ColPaliForRetrievalãƒ¢ãƒ‡ãƒ«
        processor: ColPaliProcessor
        images: PILç”»åƒã®ãƒªã‚¹ãƒˆ
        embedding_type: "128dim" (æ¤œç´¢ç”¨) ã¾ãŸã¯ "2048dim" (Gemmaã®ä¸–ç•Œ)
        device: ãƒ‡ãƒã‚¤ã‚¹ ("auto", "cuda", "mps", "cpu")
    
    Returns:
        embeddings: ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ (batch_size, N_tokens, dim)
        info: æƒ…å ±è¾æ›¸ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€æ¬¡å…ƒæ•°ãªã©ï¼‰
    """
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if device == "auto":
        if torch.cuda.is_available():
            device = "cuda:0"
        elif torch.backends.mps.is_available():
            device = "mps"
        else:
            device = "cpu"
    
    model = model.to(device)
    model.eval()
    
    # ç”»åƒã‚’å‡¦ç†
    batch_images = processor(images=images).to(device)
    
    # Forward pass
    with torch.no_grad():
        if embedding_type == "2048dim":
            # Gemmaã®2,048æ¬¡å…ƒã‚’å–å¾—ï¼ˆprojå‰ï¼‰
            # ColPaliForRetrievalã®å†…éƒ¨æ§‹é€ :
            #   model.vlm = PaliGemmaForConditionalGeneration
            #   model.embedding_proj_layer = Linear(2048, 128)
            # vlmã‚’ç›´æ¥ä½¿ç”¨ã—ã¦hidden_statesã‚’å–å¾—
            outputs = model.vlm(
                **batch_images,
                output_hidden_states=True
            )
            embeddings = outputs.hidden_states[-1]  # (batch_size, N_tokens, 2048)
            
            # ãƒã‚¹ã‚­ãƒ³ã‚°é©ç”¨
            attention_mask = batch_images["attention_mask"].unsqueeze(-1)
            embeddings = embeddings * attention_mask
            
        else:  # "128dim"
            # é€šå¸¸ã®ColPaliå‡ºåŠ›ï¼ˆ128æ¬¡å…ƒï¼‰
            outputs = model(**batch_images)
            embeddings = outputs.embeddings  # (batch_size, N_tokens, 128)
    
    # æƒ…å ±ã‚’åé›†
    batch_size, n_tokens, dim = embeddings.shape
    info = {
        "batch_size": batch_size,
        "n_tokens": n_tokens,
        "embedding_dim": dim,
        "device": device,
        "embedding_type": embedding_type
    }
    
    return embeddings, info


def apply_pooling(
    embeddings: torch.Tensor,
    method: Literal["mean", "max", "std", "concat"] = "mean"
) -> torch.Tensor:
    """
    ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã—ã¦å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
    
    Args:
        embeddings: ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ« (batch_size, N_tokens, dim)
        method: ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•
            - "mean": å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "max": æœ€å¤§å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "std": æ¨™æº–åå·®ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            - "concat": Mean + Max + Std ã‚’é€£çµï¼ˆ3å€ã®æ¬¡å…ƒï¼‰
    
    Returns:
        pooled: å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ« (batch_size, dim) ã¾ãŸã¯ (batch_size, dim*3)
    """
    if method == "mean":
        return embeddings.mean(dim=1)  # (batch_size, dim)
    
    elif method == "max":
        return embeddings.max(dim=1)[0]  # (batch_size, dim)
    
    elif method == "std":
        return embeddings.std(dim=1)  # (batch_size, dim)
    
    elif method == "concat":
        mean_pool = embeddings.mean(dim=1)
        max_pool = embeddings.max(dim=1)[0]
        std_pool = embeddings.std(dim=1)
        return torch.cat([mean_pool, max_pool, std_pool], dim=-1)  # (batch_size, dim*3)
    
    else:
        raise ValueError(f"Unknown pooling method: {method}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="ColPali - ç”»åƒã‹ã‚‰ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º")
    parser.add_argument(
        "--image",
        type=str,
        required=True,
        help="å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--model-name",
        type=str,
        default="vidore/colpali-v1.3-hf",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆHuggingFaceï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: vidore/colpali-v1.3-hfï¼ˆtransformersãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆï¼‰"
    )
    parser.add_argument(
        "--embedding-type",
        type=str,
        choices=["128dim", "2048dim"],
        default="128dim",
        help="åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒ: 128dim (æ¤œç´¢ç”¨) ã¾ãŸã¯ 2048dim (Gemmaã®ä¸–ç•Œ)"
    )
    parser.add_argument(
        "--pooling",
        type=str,
        choices=["none", "mean", "max", "std", "concat"],
        default="none",
        help="ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="ãƒ‡ãƒã‚¤ã‚¹ (auto, cuda, mps, cpu)"
    )
    
    args = parser.parse_args()
    
    # HuggingFaceèªè¨¼ã‚’è¨­å®š
    print("ğŸ” HuggingFaceèªè¨¼ã‚’è¨­å®šä¸­...")
    setup_hf_auth()
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    print(f"\nğŸ“¸ ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­: {args.image}")
    image_path = Path(args.image)
    if not image_path.exists():
        raise FileNotFoundError(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.image}")
    
    image = Image.open(image_path).convert("RGB")
    print(f"   ç”»åƒã‚µã‚¤ã‚º: {image.size}")
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰
    # transformersã®ãƒã‚¤ãƒ†ã‚£ãƒ–å®Ÿè£…ã‚’ä½¿ç”¨
    print(f"\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {args.model_name}")
    print("   ï¼ˆtransformersãƒã‚¤ãƒ†ã‚£ãƒ–å®Ÿè£… ColPaliForRetrieval ã‚’ä½¿ç”¨ï¼‰")
    
    from transformers import ColPaliForRetrieval, ColPaliProcessor
    
    model = ColPaliForRetrieval.from_pretrained(
        args.model_name,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    ).eval()
    
    processor = ColPaliProcessor.from_pretrained(args.model_name)
    print("   âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    
    # åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
    print(f"\nğŸ”„ {args.embedding_type} åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ä¸­...")
    embeddings, info = get_embeddings(
        model=model,
        processor=processor,
        images=[image],
        embedding_type=args.embedding_type,
        device=args.device
    )
    
    print(f"\nğŸ“Š ãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æƒ…å ±:")
    print(f"   - ãƒãƒƒãƒã‚µã‚¤ã‚º: {info['batch_size']}")
    print(f"   - ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {info['n_tokens']}")
    print(f"   - åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {info['embedding_dim']}")
    print(f"   - ãƒ‡ãƒã‚¤ã‚¹: {info['device']}")
    print(f"   - shape: {tuple(embeddings.shape)}")
    
    # ãƒ—ãƒ¼ãƒªãƒ³ã‚°é©ç”¨
    if args.pooling != "none":
        print(f"\nğŸ¯ {args.pooling.upper()} ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’é©ç”¨ä¸­...")
        pooled = apply_pooling(embeddings, method=args.pooling)
        print(f"   å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ« shape: {tuple(pooled.shape)}")
        
        # BFloat16ã¯numpyã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€float32ã«å¤‰æ›
        pooled_numpy = pooled.cpu().float().numpy()
        
        print(f"\nâœ… å®Œäº†ï¼")
        print(f"\nğŸ’¡ ä½¿ç”¨ä¾‹:")
        print(f"   ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’LightGBMã‚„SVRã«å…¥åŠ›ã—ã¦ã€OCRå“è³ªäºˆæ¸¬ãŒå¯èƒ½ã§ã™ã€‚")
        print(f"   ä¾‹: pooled_vector.cpu().float().numpy() â†’ shape: {tuple(pooled_numpy.shape)}")
    else:
        print(f"\nâœ… å®Œäº†ï¼")
        print(f"\nğŸ’¡ ä½¿ç”¨ä¾‹:")
        print(f"   1. Late Interaction (MaxSim) ã§æ¤œç´¢ã«ä½¿ç”¨")
        print(f"   2. Poolingã‚’é©ç”¨ã—ã¦å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›")


if __name__ == "__main__":
    main()
